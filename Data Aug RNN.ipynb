{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0 cpu\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import io\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import time\n",
    "import sys\n",
    "PAD, BOS, EOS = '<pad>', '<bos>', '<eos>'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.set_printoptions(profile=8)\n",
    "print(torch.__version__, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    # in和out分别是input和output的缩写\n",
    "    corpus_indices, tokens_dic, in_seqs = [], {}, []\n",
    "    with open('../../NLP/Code/Dive-into-DL-PyTorch-master/data/sst2_train_500.txt') as f:\n",
    "        lines = f.readlines()\n",
    "        list_l = []\n",
    "        for line in lines:\n",
    "            list_l.append(line.split('\\t')[1])\n",
    "        lines = ''.join(list_l)\n",
    "    corpus = lines.replace('\\n', ' ').replace('\\r', ' ')\n",
    "#     print('corpus', corpus)\n",
    "    in_seq_tokens = corpus.split(' ') # split every word in the sentence accodording to the blank ' '.\n",
    "#     print('in_seq_tokens',in_seq_tokens)\n",
    "    tokens_dic = dict([(char, i) for i, char in enumerate(in_seq_tokens)]) # ['fs': 1, 'is':2.....]char_to_idx\n",
    "#     print('tokens_dic', tokens_dic)\n",
    "    vocab_size = len(in_seq_tokens)\n",
    "    corpus_indices = [tokens_dic[char] for char in in_seq_tokens] # word2number [1,2,3,4,12,...]\n",
    "    return corpus_indices, tokens_dic, in_seq_tokens, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8897"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_indices, tokens_dic, in_seq_tokens, vocab_size = read_data() # dataset 是输入句子和输出句子转换成字典表示的集合.\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, drop_prob = 0):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, hidden_size, dropout=drop_prob)\n",
    "        self.dense = nn.Linear(hidden_size, vocab_size)\n",
    "        self.state = None\n",
    "\n",
    "    def forward(self, inputs, state): # inputs: (batch, seq_len)\n",
    "        embedding = self.embedding(inputs.to(torch.int64))\n",
    "#         print('embedding', embedding.shape)\n",
    "        Y, self.state = self.rnn(embedding, state)\n",
    "#         print('output Y', Y.shape)\n",
    "#         print('output Y[:,-1,:]', Y[:,-1,:].shape)\n",
    "        output = self.dense(Y[:,-1,:])\n",
    "#         print('final output', output)\n",
    "#         print('final output size', output.shape)\n",
    "        return output, self.state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n",
    "                      char_to_idx):\n",
    "\n",
    "    state = None\n",
    "    output = [char_to_idx[prefix.split(' ')[0]]] # n[-1] means the last item in the list n [burger]\n",
    "    # output会记录prefix加上输出. 初始状态时记录该词第一个字在字典的index, 'burger'git词典上'burger: 1, output = 1   \n",
    "    for t in range(num_chars + len(prefix.split(' ')) - 1): # t[0, 13)\n",
    "        X = torch.tensor([output[-1]], device=device).view(1, 1) # 用最外层的word当作输入, 这里的第一个word 是输入的第一个字，即burger\n",
    "        if state is not None:\n",
    "            if isinstance(state, tuple): # LSTM, state:(h, c)  \n",
    "                state = (state[0].to(device), state[1].to(device))\n",
    "            else:   \n",
    "                state = state.to(device)\n",
    "        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n",
    "        if t < len(prefix.split()) - 1: # if t<2-1=1\n",
    "            output.append(char_to_idx[prefix.split()[t + 1]]) #实际上没用上这次的预测值，直接加上原来的值\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))    \n",
    "    sequence = []\n",
    "    for i in output:\n",
    "        sequence.append(' ')\n",
    "        sequence.append(idx_to_char[i])\n",
    "\n",
    "    return ''.join(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n",
    "                      char_to_idx):\n",
    "    state = None\n",
    "    output = [char_to_idx[prefix.split()[i]] for i in range(len(prefix.split()))]\n",
    "    print('prefix length', output)\n",
    "#     output = char_to_idx[prefix.split()[:]]\n",
    "    for t in range(num_chars):\n",
    "        if state is not None:\n",
    "            if isinstance(state, tuple): # LSTM, state:(h, c)  \n",
    "                state = (state[0].to(device), state[1].to(device))\n",
    "            else:   \n",
    "                state = state.to(device)\n",
    "        if len(output) < 3:\n",
    "            X = torch.tensor([output[-1]], device=device).view(1, 1)\n",
    "            \n",
    "        else:\n",
    "            X = torch.tensor([output[-3]], device=device).view(1, 1)\n",
    "        \n",
    "        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n",
    "#         if t < len(prefix.split()) - 1: # if t<3-1=2\n",
    "#             output.append(char_to_idx[prefix.split()[t + 1]]) #实际上没用上这次的预测值，直接加上原来的值\n",
    "#         else:\n",
    "        output.append(int(Y.argmax(dim=1).item()))    \n",
    "    sequence = []\n",
    "    for i in output:\n",
    "        sequence.append(' ')\n",
    "        sequence.append(idx_to_char[i])\n",
    "\n",
    "    return ''.join(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 5\n",
    "hidden_size = 256\n",
    "model = RNNModel(vocab_size, embed_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix length [8559, 1, 8843]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' his burger is hunger considered small a is is even it it considered ever ever'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn_pytorch('his burger is', 12, model, vocab_size, device, in_seq_tokens, tokens_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    corpus_indices = torch.tensor(corpus_indices, device=device)\n",
    "#     print('corpus_indices', corpus_indices)\n",
    "    data_len = len(corpus_indices)\n",
    "#     print('data_len', data_len)\n",
    "    batch_len = data_len // batch_size\n",
    "#     print('batch_len', batch_len)\n",
    "    indices = corpus_indices[0: batch_size*batch_len].view(batch_size, batch_len)\n",
    "#     print('indices', indices)\n",
    "#     print('indices', indices.shape)\n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "#     print('epoch_size', epoch_size)\n",
    "    for i in range(epoch_size):\n",
    "#         i = i * num_steps\n",
    "        X = indices[:, i: i + num_steps]\n",
    "#         print('X', X)\n",
    "        Y = indices[:, i + num_steps + 1]\n",
    "#         print('Y', Y)\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_pytorch(model, vocab_size, device,\n",
    "                                corpus_indices, idx_to_char, char_to_idx,\n",
    "                                num_epochs, num_steps, lr, clipping_theta,\n",
    "                                batch_size, pred_period, pred_len, prefixes):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    state = None\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样\n",
    "        for X, Y in data_iter:\n",
    "            if state is not None:\n",
    "                # 使用detach函数从计算图分离隐藏状态, 这是为了\n",
    "                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\n",
    "                if isinstance (state, tuple): # LSTM, state:(h, c)  \n",
    "                    state = (state[0].detach(), state[1].detach())\n",
    "                else:   \n",
    "                    state = state.detach()\n",
    "#             print('X is', X)\n",
    "#             print('X_shape is', X.shape)\n",
    "#             print('Y is', Y)\n",
    "#             print('Y_shape is', Y.shape)\n",
    "            (output, state) = model(X, state) # output: 形状为(num_steps * batch_size, vocab_size)\n",
    "            # Y的形状是(batch_size, num_steps)，转置后再变成长度为\n",
    "            # batch * num_steps 的向量，这样跟输出的行一一对应\n",
    "#             print('output', output)\n",
    "#             print('output_size', output.shape)\n",
    "#             y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "#             print('y', y)\n",
    "            y = Y\n",
    "            l = loss(output, Y.long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "        try:\n",
    "            perplexity = math.exp(l_sum / n)\n",
    "        except OverflowError:\n",
    "            perplexity = float('inf')\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "                epoch + 1, perplexity, time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn_pytorch(\n",
    "                    prefix, pred_len, model, vocab_size, device, idx_to_char,\n",
    "                    char_to_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, perplexity 297.813557, time 3.70 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger nt is  of her is  not  is\n",
      "prefix length [7402, 114]\n",
      " -  their pants  and  is  is  is  is\n",
      "epoch 10, perplexity 97.926435, time 3.71 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday fabric consistently say life not a is  runs\n",
      "prefix length [7402, 114]\n",
      " -  their pants leaky and leaky is  is strangers is something a\n",
      "epoch 15, perplexity 17.904346, time 3.69 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday fabric shallow video snake tell half so exquisite both\n",
      "prefix length [7402, 114]\n",
      " -  their pants latest diversion leaky us new it shiri serious  the\n",
      "epoch 20, perplexity 5.813412, time 3.74 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday fabric shallow video snake tell half so exquisite both\n",
      "prefix length [7402, 114]\n",
      " -  their pants latest diversion diversion moments new spontaneous is value there sincerely\n",
      "epoch 25, perplexity 2.402053, time 3.69 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday fabric nt video about video half reading empty screen\n",
      "prefix length [7402, 114]\n",
      " -  their pants latest diversion diversion moments tell spontaneous humor anti a jarring\n",
      "epoch 30, perplexity 1.640727, time 3.88 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday fabric nt poetry snake video strong affleck without because\n",
      "prefix length [7402, 114]\n",
      " -  their pants latest diversion diversion moments tell tell less value value aims\n",
      "epoch 35, perplexity 1.453234, time 3.71 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday fabric nt video quite moment half value  a\n",
      "prefix length [7402, 114]\n",
      " -  their pants leaky diversion diversion  tell spontaneous somewhat lead a series\n",
      "epoch 40, perplexity 1.103435, time 3.71 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday moment nt poetry spectacle spy of felt feel avengers\n",
      "prefix length [7402, 114]\n",
      " -  their pants leaky diversion diversion emerge tell effort moments cletis little highly\n",
      "epoch 45, perplexity 1.048723, time 3.71 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday suspects nt poetry spectacle series dvd felt  autobiographical\n",
      "prefix length [7402, 114]\n",
      " -  their pants leaky diversion diversion  tell effort somewhat whatsoever a indulgent\n",
      "epoch 50, perplexity 1.031574, time 3.73 sec\n",
      "prefix length [8878, 1]\n",
      " -  the burger saturday suspects nt poetry spectacle series dvd felt  autobiographical\n",
      "prefix length [7402, 114]\n",
      " -  their pants leaky diversion diversion  tell effort somewhat whatsoever a adaptation\n"
     ]
    }
   ],
   "source": [
    "num_epochs, batch_size, lr, clipping_theta, num_steps= 50, 32, 1e-3, 1e-2, 3 # 注意这里的学习率设置\n",
    "pred_period, pred_len, prefixes = 5, 10, ['the burger', 'their pants']\n",
    "train_and_predict_rnn_pytorch(model, vocab_size, device,\n",
    "                            corpus_indices, in_seq_tokens, tokens_dic,\n",
    "                            num_epochs, num_steps, lr, clipping_theta,\n",
    "                            batch_size, pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
